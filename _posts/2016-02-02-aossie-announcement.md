---
layout: post
title:  "AOSSIE: Google Summer of Code at the ANU"
date:   2016-02-02 13:50:58 +1100
---

In 2016, the Australian National University (ANU) is participating in
the Google Summer of Code (GSoC) program as the AOSSIE umbrella
organisation including four great research-intensive open-source
projects developed at the ANU:

- The **Extempore** live programming environment
- The **PriMedLink** Private Medical Data Linkage project
- The **Rogas** network analytics platform
- The **Skeptik** tool for compressing proofs generated by automated reasoners

AOSSIE stands for **A**NU's **O**pen-**S**ource **S**oftware **I**nnovation and **E**ducation.

If you'd like to participate, here's the process:

- look at the projects and ideas below
- [contact us](mailto:aossie-gsoc-2016@googlegroups.com) before the application period (29 February - 13 March) to discuss your application
- write your application according to our template
- [submit your application](TODO link here) (14 March - 25 March)

Please read the [FAQ](please read the [FAQ](https://developers.google.com/open-source/gsoc/faq)) to learn more.

You'll get a chance to hack on exciting open-source projects, build up your GitHub resume, get access to expert mentors from the ANU, and be the envy of your friends!


# Projects and Ideas

## Extempore

![Extempore](logos/extempore.png)

Extempore is an [open-source](https://github.com/digego/extempore)
(MIT Licence) programming language and runtime environment designed to
support live programming---a human programmer operating as an active
agent in a real-time distributed network of environmentally aware
systems. The programmer interacts with the distributed real-time
system by modifying code on-the-fly.

Extempore provides a completely hot-swappable runtime environment with
a strong temporal semantics, a flexible concurrency architecture,
builtin support for distributed computing, and aims to provide
flexible compiler-as-a-service functionality. Extempore makes
extensive use of LLVM project to JIT-compile efficient native code in
real-time.

To see Extempore in action, see Andrew's talks at
[OSCON](https://www.youtube.com/watch?v=yY1FSsUV-8c) (10mins) for a
brief overview or [GOTO](https://www.youtube.com/watch?v=Sg2BjFQnr9s)
(45mins) for a more in-depth presentation.

### Project idea #1: Live programming with scientific simulation codes

**Description**

Running codes in batch mode is the norm in scientific computing, with
good reason---pity the poor grad student who would otherwise have to
stay awake all night interactively triggering simulation runs during a
parameter sweep! However, this workflow also has disadvantages,
especially in the early stages of developing new codes or tackling new
problem domains. This project would involve using Extempore to
interact with running scientific simulation codes---inserting
debugging code, tuning parameters and hot-swapping subroutines---to
better understand what the codes are doing (or not doing) and to give
new insights into the underlying science.

Extempore has already been used for
[interactive steering of particle-in-cell (PIC) plasma physics simulation codes](https://vimeo.com/99891379).
This project provides an opportunity to continue this work, working
with both live programmers and physicists at the ANU and overseas to
harness and profile plasma physics PIC codes in this live programming
workflow.

This project will apply a modern live-coding tools & techniques to a
common problem in the scientific simulation community---how to
"breathe life" into legacy simulation codes. Often these codes are
used for many years (or decades!) after they were first developed.
They are often used by experimental scientists to model experiments
which are quite different from those existing when the simulations
were first developed. In the absence of the original programmers,
there is a need to bring these simulations back to life and to return
them to the experimentalists with modern user interfaces and
functionality.

This project would involve:
- prototyping simulations on parallel computers under real-time
  control in Extempore
- implementing library/tooling support in Extempore to provide a
  programmer with appropriate feedback and control of a simulation
- evaluating the opportunities and challenges of live steering in this
  context (e.g. what safeguards must the tooling provide, what
  timescales and algorithmic "granularity" provides the most fruitful
  domain for live steering)
- working with domain expert physicists to understand & interpret the
  results of the computation

**Requirements/Prerequisites**

- programming skills (especially C, but some Lisp knowledge would be
  helpful too)
- experience with scientific and numerical computation
- parallel programming

**Benefit for the Student**

- the chance to work with real computational physicists, doing real
  science
- design, build and evaluate programming tools & interfaces in
  Extempore which will be used by other scientists

**Benefit for the Project**

Extempore has been used for interactive scientific simulation in the
past, but mostly in an ad-hoc manner. This project would allow a
student to take a big-picture view of the libraries & other
infrastructure to help more scientists incorporate some live
interactivity into their simulation workflow. The libraries developed
in the project could then be extended in the future for working with
other simulation codes.

**More Information**

For more information, visit the
[Extempore homepage](http://extempore.moso.com.au) or sign up to the
[Extempore mailing list](https://groups.google.com/forum/#!forum/extemporelang).

### Project idea #2: a self-hosting xtlang compiler

**Description**

The compiler for Extempore's native language, xtlang, is currently
written in Scheme. It is desirable for Extempore to eventually become
self-hosting, i.e. for the xtlang compiler to be written in xtlang.

**Requirements/Prerequisites**

- compilers
- Scheme (the current compiler is written in Scheme)
- algorithms & data structures
- familiarity with LLVM a bonus

**Benefit for the Student**

- learn about compilers, type inference, in a dynamic and interactive
  environment (in Extempore, even the compiler is runtime
  hot-swappable!)
- work on the guts of Extempore, getting to know the system in-depth

**Benefit for the Project**

The current Scheme implementation of the xtlang compiler works well,
but is slow, especially when working with generic functions, which
xtlang supports. Re-implementing the compiler in xtlang would make
compilations times (several?) orders of magnitude faster in some
cases, which is especially important in a programming environment
designed for interactive computation.

**More Information**

For more information, visit the
[Extempore homepage](http://extempore.moso.com.au) or sign up to the
[Extempore mailing list](https://groups.google.com/forum/#!forum/extemporelang).

<!-- ### Project idea #3: interactive data analysis/visualisation framework for streaming data -->

<!-- **Description** -->

<!-- **Requirements/Prerequisites** -->

<!-- **Benefit for the Student** -->

<!-- **Benefit for the Project** -->

<!-- **More Information** -->

## PriMedLink
[PriMedLink](logos/PriMedLink.jpg)

Information technology has increasingly been used to support healthcare applications and clinical research. Medical data are recorded electronically to enable better patient care, resource management, advanced treatments, detection and prevention of diseases, risk management, clinical trials, and health surveillance more efficiently and effectively. Such digital medical data also support clinical research through the linkage and aggregation of records corresponding to same patients, matching of similar patients, and statistical analysis of observations gathered from populations of patients.

Due to the absence of unique entity identifiers in different databases, often personal identifying attributes such as names, addresses, ages or dates of birth of patients, or their medical attributes such as blood pressure, cholesterol level, or body weight mass have to be used for the linkage, matching, or analytics. Increasing concerns of privacy and confidentiality, however, preclude the exchange or sharing of such medical data across different organizations for data aggregation and analysis. Techniques are required to conduct data matching or linkage on masked (encoded) medical data such that no sensitive information is revealed to any party involved in the linkage or any other external parties.

Several data masking (encoding) techniques have been developed in the literature (privacy-preserving data mining and privacy-preserving record linkage) to allow matching and linking of masked data without compromising privacy. However, medical data brings its own challenges which need to be tackled to make Private Medical Data Linkage (PriMedLink) research feasible and practical in real settings. The ultimate goal of this project is to develop open source software addressing these challenges for PriMedLink which would allow researchers and practitioners to learn and apply techniques for private matching and linking of medical data, and develop enhanced techniques further towards this novel and emerging research direction.

**License:** [GPL-3.0](http://opensource.org/licenses/GPL-3.0)
**Code Repository:** [Privacy-Preserving Similar Patient Matching Code](https://dmm.anu.edu.au/PPSPM/PPSPM Software.zip)

### PriMedLink's Project Idea 1: Space/time efficient privacy-preserving medical data representation

**Description**

A medical datum is a single observation of a patient that generally comprises of four elements: 1) the patient in question (generally identified by personal identifying values such as names, addresses, and contact details), 2) the parameter being observed (such as blood pressure, cholesterol level, age, and body weight), 3) the value of these parameters, and 4) the time of the observation (date and time of recorded). Medical data are multiple such observations. This includes several different observations made concurrently, observations of the same patient parameter made at several points in time, or both. Therefore, medical data are often longitudinal and of different types ranging from narrative, textual data to numerical measurements, recorded signals, drawings, and images and videos.

Representing such complex data efficiently in terms of space and time is a challenging aspect that has been researched over several decades. However, efficient and privacy-preserving (i.e. masked) medical data representation is an interesting research direction that requires more attention for PriMedLink research and applications to enable medical data linkage and matching without compromising patient data privacy.

The aim of this project is to research and develop efficient (in terms of memory space and computational complexities) data structures and masking functions for representing medical data in a privacy-preserving manner that will allow novel forms of linkage, matching, and analysis for PriMedLink.

**Benefit for the Student:**

Private medical data linkage is an emerging research field and is being widely required in many real health applications. This project allows the student to gain exposure to medical data storage and processing and privacy aspects in medical data linkage that would help to contribute to applied research in healthcare applications.

**Benefit for the Project:**

This contributes a baseline for private medical data linkage (PriMedLink) that would have a high impact in the healthcare and research industries.

**Requirements/ Prerequisites:**

Interested students should have good programming skills (ideally including in Python) and background knowledge in algorithms and data structures, data mining, and privacy.

It is of advantage if students have knowledge in medical data storage, data management, analysis and mining and/or have successfully attended some courses on databases, data structures and algorithms, data mining, cryptography, or health informatics.

**Mentors**

Dinusha Vatsalan, Peter Christen

**More Information:**

The following materials provide specific background literature on medical data, different data structures used for medical data storage and representation, and different masking functions for privacy-preservation that will be required to conduct the project.

* A taxonomy of privacy-preserving record linkage techniques. Dinusha
  Vatsalan, Peter Christen, and Vassilios S. Verykios, Elsevier
  Journal of Information Systems 2013,
  (http://www.sciencedirect.com/science/article/pii/S0306437912001470)

* Data driven analytics in Healthcare: Problems, Challenges, and
  Future Directions (Fei Wang, ACM CIKM 2014,
  https://sites.google.com/site/feiwang03/cikm14-tutorial)

* Medical Data: Their acquisition, storage, and use. Edward H.
  Shortliffe and G. Octo Barnett, ACM Medical Informatics: Computer
  Applications in Healthcare,
  (http://dl.acm.org/citation.cfm?id=87788)

* Standardized vectorial representation of medical data in patient
  records. Wolfgang Orthuber and Efthymios Papavramidis, Medical and
  Care Compunetics 2010, (http://www.orthuber.com/wICMCC2010.pdf)

### PriMedLink's Project idea 2: Private medical data comparison functions for similar patient matching

**Description**

Privacy-preserving similar patient matching ([PPSPM](http://dmm.anu.edu.au/PPSPM/)) is a core component of PriMedLink. Identifying patients with similar characteristics or conditions is required in several healthcare applications such as clinical trials, inpatient bed management, and advanced or personalized treatment. Due to privacy and confidentiality concerns, similar patient matching needs to be conducted using masked (encoded) records.

Bloom filter based encoding is one efficient data masking technique that has widely been used in the literature as it allows approximate matching of attribute values (i.e. errors and variations in the attribute values are considered when matching) while preserving privacy.

However, all the existing Bloom filter encoding based PPRL techniques only support approximate matching of string or categorical data types. Since matching of different data types such as integer, float, date, time, scan image, textual data, medical reports, and geographical data is commonly required in PriMedLink, developing approximate matching techniques for different data types using Bloom filter based encoding is an important research direction.

We have recently conducted some initial work on approximate matching of Bloom filter encoded integer, float, and modulus data types (which has been published in the Journal of Biomedical Informatics). The aim of this project is to research and implement advanced techniques for approximate matching of other different types of medical data (such as textual data, image data, geographical data) masked using Bloom filter based encoding privacy technique.

**Benefit for the Student:**

Privacy-preserving techniques are evolving and challenging research topics due to the increasing concerns of privacy in big data. This project involves studies on novel and viable techniques for data masking and matching using advanced and cutting edge techniques for practical PriMedLink applications.

**Benefit for the Project:**

This will project extend the scope of PriMedLink and provide a baseline for matching different types of medical data in a privacy-preserving setting.

**Requirements/ Prerequisites:**

Interested students should have good programming skills (ideally including in Python) and background knowledge in algorithms and data structures, data mining, and string comparison.

It is of advantage if students working on this project have knowledge in privacy aspects of data analysis and data mining and/or have successfully attended some courses on databases, data structures and algorithms, data mining, cryptography, or health informatics.

**Mentors**

Dinusha Vatsalan, Peter Christen

**More Information:**

The following background materials provide some basic understandings on data masking and similarity calculations for approximate matching.

* Privacy-preserving matching of similar patients. Dinusha Vatsalan
  and Peter Christen, Elsevier Journal of Biomedical Informatics,
  2016,
  (http://www.sciencedirect.com/science/article/pii/S1532046415002841)

* A taxonomy of privacy-preserving record linkage techniques. Dinusha
  Vatsalan, Peter Christen, and Vassilios S. Verykios, Elsevier
  Journal of Information Systems 2013,
  (http://www.sciencedirect.com/science/article/pii/S0306437912001470)

* Data Matching: Concepts and Techniques for Record Linkage, Entity
  Resolution, and Duplicate Detection. Peter Christen, Springer
  Data-Centric Systems and Applications 2012,
  (http://www.springer.com/gp/book/9783642311635)
  

### PriMedLink's Project idea 3: Flexible and realistic synthetic medical data generator

**Description**

Clinical research and development requires medical data for evaluation of new algorithms and systems. However, privacy and confidentiality concerns impede the collection or sharing of such medical data across different organizations. An alternative is to generate synthetic medical test data for the evaluation of clinical research. Few data generators have been developed so far for medical test data. An important aspect of such medical data generators is that they should be able to generate data that exhibit real-world characteristics. To the best of our knowledge, there is no such realistic medical test data generator freely available for clinical research evaluation and development.

Medical data are longitudinal and contain different types ranging from narrative, textual data to numerical measurements, recorded signals, drawings, and images and videos. There have been several internationally accepted codes of diseases, drugs, etc. used in healthcare systems and applications. Developing a flexible and extensible tool that can generate realistic longitudinal medical data incorporating different data types and standard codes would be a useful direction for clinical research and health data analytics.

The project aims to develop a synthetic data generator tool for medical data with preserved various original data characteristics. We have previously developed an online synthetic data generator for personal data (https://dmm.anu.edu.au/geco/). The goals of this project are:
1. Study and analyze standards, codes and different types of medical data.
2. Design and develop a tool for synthetic medical data generation by modelling real data characteristics and relationships.
3. Test the tool by generating and analyzing different sets of medical data using the proposed tool.

It is of advantage if students have knowledge in medical data representation, analysis and mining and/or have successfully attended some courses on databases, data structures and algorithms, data mining, or health informatics.

**Benefit for the Student:**

Medical data linkage and research has emerged as a promising field in healthcare industry. This project allows the student to learn the basics of medical data generation, representation and storage, and to contribute to an important problem in the medical data research and development.

**Benefit for the Project:**

Much research in medical data linkage, mining and analytics rely on some medical test data for evaluating and comparing new techniques and algorithms. The proposed online freely available synthetic medical data generator would greatly help researchers in this field.

**Requirements/ Prerequisites:**

Interested students should have good programming skills (ideally including in Python) and background knowledge in algorithms and data structures, and software engineering.

**Mentors**

Dinusha Vatsalan, Peter Christen

**More Information:**

The following materials provide specific background literature on medical data, different data types, and characteristics of synthetic data generators that will be required to conduct the project.

* Flexible and extensible generation and corruption of personal data.
  Peter Christen and Dinusha Vatsalan, ACM CIKM 2014,
  (http://dl.acm.org/citation.cfm?id=2507815)

* GeCo: an online personal data generator and corruptor. Khoi-Nguyen
  Tran, Dinusha Vatsalan, and Peter Christen, ACM CIKM 2014,
  (http://dl.acm.org/citation.cfm?id=2508207)

* Medical Data: Their acquisition, storage, and use. Edward H.
  Shortliffe and G. Octo Barnett, ACM Medical Informatics: Computer
  Applications in Healthcare, (http://dl.acm.org/citation.cfm?id=87788)

* A Method for Generation and Distribution of Synthetic Medical Record
  Data for Evaluation of Disease-Monitoring System. Joseph S. Lombardo
  and Linda J. Moniz, Johns Hopkins APL Technical Digest 2008,
  (http://techdigest.jhuapl.edu/TD/td2704/LombardoMethod.pdf)

* Customized test data generator for HL7v3 based healthcare
  information systems. Alexandru Egner et al., Journal of Control
  Engineering and Applied Informatics 2013,
  (http://www.ceai.srait.ro/index.php/ceai/article/view/1287/1260)


## Rogas
![Rogas](logos/Rogas.png)

[Rogas](https://github.com/CornucopiaRG/Rogas) is a platform for network analytics which integrates a collection of graph analysis tools and algorithms into a unified framework in order to support various network analysis tasks efficiently and effectively. 

The Rogas platform has a relational core for storing network data. It can provide an integrated view of performed network analytics tasks, allow us to check the semantic integrity of network data, and help us understand how analysis queries interact with each other. It also supports comparative network analytics in a dynamical modelling environment. At its core, Rogas uses a query engine, called RG engine, to handle (possibly interactive) relational and graph queries of network analytics tasks. The RG engine is built upon the open-source database system PostgreSQL by extending the query engine of PostgreSQL with the query processing and optimization of graphs.

**License:** [GPL-3.0](http://opensource.org/licenses/GPL-3.0)
**Code Repository:** [Rogas' Code in Github](https://github.com/CornucopiaRG/Rogas)

### Rogas's Project Idea 1: Graph Query Optimization

**Description**

Network analysis queries are often computationally expensive. An efficient query optimizer is vital for efficiency of processing network analysis queries over graphs, relations, or a mix of them. The query engine in Rogas supports an extended SQL query language, called RG-SQL, which incorporates a number of primitive graph constructors and relational algebra operators in a unified manner. 

The goal of this project is to determine the most efficient way to execute RG-SQL queries by considering the possible query plans. This requires:

- building the statistic modelling for different query patterns 
- analysing how relational data and graph data are used in queries, in relating to their storage and processing models
- rewriting queries based on the algebraic properties of graph constructors and relational algebra operators

**Benefit for the Student**

Gain a solid understanding of latest technologies and tools for graph analytics. Get hands on experience in developing a query engines for processing and optimizing queries over graphs.

**Benefit for the Project**

The development of an efficient query optimizer may improve the performance of network analysis queries. It will also provide a robust foundation for implementing graph analytics algorithms and tools within Rogas in the future.

**Requirements**

Strong skills in software development (Java, Python or C) and solid knowledge in database theory and implementation are required. Background knowledge in machine learning is also desired.

**Mentors**

Qing Wang, Minjian Liu

**More information**

[1].	S. Abiteboul, R. Hull and V. Vianu, "Foundations of databases". Addison-Wesley Reading, 1995.

[2].	P. Zhao and J. Han, "On graph query optimization in large networks". Proceedings of the VLDB Endowment, 2010.

[3].	S. Sakr, S. Elnikety and Y. He, "G-SPARQL: a hybrid engine for querying large attributed graphs". Proceedings of the 21st ACM international conference on Information and knowledge management, 2012.


### Rogas's Project Idea 2: Integrity Constraints of Graphs

**Description**

With more and more network analysis queries being performed from different perspectives, it becomes increasingly important to semantically align and mine their relationships. But how can we tell, given a number of network analysis queries, whether or not they are semantically relevant and consistent?

The goal of this project is to develop and implement practically useful integrity constraints over different types of graphs. This includes designing an automated verification approach that can detect inconsistencies of these graphs and determine their causes.

**Benefit for the Student**

Gain a solid understanding of latest technologies and tools for graph analytics. Get hands on experience in implementing integrity constraints over graphs and designing an automated verification approach.

**Benefit for the Project**

The development of integrity constraints is an important aspect of the RG framework. Specifying integrity constraints over graphs can bring several benefits for network analysis applications: (1) It enables semantic integrity checking across different analysis results. (2) It supports comparative analysis on different dimensions in order to predict trends and discover new insights. (3) It can improve query performance by reformulating queries in a way that can leverage existing results whenever possible.

**Requirements**

Strong skills in software development (Java, Python or C), and solid knowledge in database theory and graph theory are desired.

**Mentors**

Qing Wang, Minjian Liu

**More information**

[1].	Q. Wang, "Network analytics ER model -- Towards a conceptual view of network analytics". Proceedings of ER, 2014.

[2].	S. Abiteboul, R. Hull and V. Vianu, "Foundations of databases". Addison-Wesley Reading, 1995.

### Rogas's Project Idea 3: Dynamic Network Analysis

**Description**

Network analysis applications are “dynamic” by nature, and evolve over time. Can network analysis be dynamically performed at different scales or over different time periods so as to predict trends and patterns? To cope with this, the Rogas platform should be extended to support a variety of techniques for dynamic analysis of network data. 

The goal of this project is to develop techniques that can support dynamic network analysis tasks. This consists of two tasks: (1) developing a visualization tool that can visualize graphs dynamically, and (2) designing dynamic analysis strategies that can provide a flexible and efficient way for conducting various network analysis tasks dynamically. 


**Benefit for the Student**

Gain a solid understanding of latest technologies and tools for graph analytics. Get hands on experience in developing visualization and analysis tools for networks.

**Benefit for the Project**

After completing this work, the RG framework can be extended to provide a dynamic view on the semantics of network analysis tasks. It also brings us some advantages for managing network analysis tasks, such as, dynamically handling the semantic integration of different data analysis results and enabling comparative network analysis.

**Requirements**

Strong skills in software development (Java, Python or C), and solid knowledge in database theory and graph theory are desired.

**Mentors**

Qing Wang, Minjian Liu

**More information**

[1].	Q. Wang, "A conceptual framework for network analytics". Data and Knowledge Engineering, 2015.

[2].	C. Aggarwal and K. Subbian, "Evolutionary Network Analysis: A Survey". ACM Computing Surveys, 47(1), 2014.



## Skeptik

![Skeptik](http://www.iue.tuwien.ac.at/cse/images/static_content/projects/skeptik_logo.png)

[Skeptik](https://github.com/Paradoxika/Skeptik) is a collection of data structures and algorithms focused on the compression of formal proofs.

Resolution proofs, in particular, are used by various sat-solvers, smt-solvers and automated theorem provers, 
as certificates of correctness for the answers they provide. These automated deduction tools have a wide 
range of application areas, from mathematics to software and hardware verification.

By providing smaller resolution proofs that are easier and faster to check, Skeptik aims at improving the 
reliability of these automated deduction tools and at facilitating the exchange of information between them.

**License:** [GPL-3.0](http://opensource.org/licenses/GPL-3.0)
**Code Repository:** [Skeptik's Code in Github](https://github.com/Paradoxika/Skeptik)


### Skeptik's Project Idea 1: Extension of proof compression algorithms from propositional to first-order logic

**Description**

Until 2013 Skeptik has focused on the compression of propositional proofs generated by sat- and SMT-solvers. In 2014, Jan Gorzny, GSoC student in 2014, has started to generalise two of the proof compression algorithms (RecyclePivotsWithIntersection and LowerUnits) to first-order proofs generated by resolution-based first-order automated theorem provers (ATPs). Nevertheless, there are still many other proof compression algorithms that deserve to be generalised to the first-order case, and Jan's algorithms could still be improved in order to handle more proofs.

Skeptik’s data structures are already general enough to handle first- and even higher-order formulas. There are general abstract data structures for proofs, but they will have to be specialised (via inheritance) to deal with specific inference rules used by various ATPs. Furthermore, a parser for proofs generated by the automated theorem prover SPASS is already available, but it handles only simple proofs that do not use the SPASS's most sophisticated inference rules. Having a fully general parser for unrestricted SPASS proofs would be useful. a combinator parser for first-order proofs in the TPTP TSTP format [1] would be very nice to have as well, since it would allow us to import proofs generated by many other theorem provers (e.g. Schultz's E prover).

The generalisation of the compression algorithms to the first-order case will involve some scientific creativity and, therefore, this is not an easy project. A solid knowledge of logic, automated deduction and basic proof theory is required.

In the previous two years, Skeptik’s GSoC students have achieved great academic success and were able to publish and present their results in high-level conferences. We are committed to provide similar opportunities to this year’s GSoC students, and we are looking for students that are enthusiastic about these opportunities! If you are interested in this project idea, please contact us as soon as possible.

[1] TSTP is the proof format used by the TPTP library of automated deduction problems maintained by Geoff Sutcliffe at the University of Miami. Google it to know more!

[2] Papers about these algorithms can be downloaded from http://www.logic.at/people/bruno . Look for the IJCAR 2014 paper describing Skeptik. It provides a good starting point to learn more about Skeptik.

**Benefit for the Student**

The student will acquire practical experience and be in touch with cutting-edge research in the fields of automated deduction and applied proof theory. He will be mentioned as a co-author of any paper that might benefit from his implementation. He will have the pleasure of programming in the awesome language Scala.

**Benefit for the Project**

Skeptik’s application scope will be further extended from propositional to first-order logic.

**Requirements**

Solid knowledge of logic, automated deduction and basic proof theory is required. Knowledge of Scala or experience with other object-oriented (e.g. Java, C++,...) and functional (e.g. Haskell, OCaml,...) programming languages and willingness to learn Scala is required. Experience with data structures for proofs or directed acyclic graphs is highly desirable.

**Mentors**

Bruno Woltzenlogel Paleo, Ekaterina Lebedeva

**More information**

Instructions on how to improve your chances of getting accepted are listed on [Skeptik's wiki](https://github.com/Paradoxika/Skeptik/wiki/GSoC-Instructions).

## Skeptik's Project Idea 2: Greedy and Heuristic Search for Minimal Congruence Closure Proofs

SMT-proofs are composed of a propositional resolution proof in the bottom and "theory proofs" in the top. The simplest theory supported by SMT-solvers is the theory of equality with uninterpreted functions. Statements in the language of this theory can be decided modulo this theory using congruence closure algorithms. In 2014, Andreas Fellner (who was GSoC student in 2012) implemented the first algorithm aiming at compressing such congruence closure proofs. His algorithm was based on a variant of Dijkstra's shortest path algorithm applied to congruence graphs. However, due to the NP-completeness of this problem, this algorithm is not able to find the shortest congruence explanation.

This project idea aims at extending Andreas's algorithm in order to guarantee that minimally short explanations are found. To achieve this, we propose a brute-force approach, in which literals in the explanation to be shortened are incrementally removed while the explanation remains invalid. The choice of which literal to remove may be done heuristically and may influence the size of the minimally short explanation.

[1] To learn more, have a look at [Andreas's MSc thesis](https://github.com/AFellner/Thesis/blob/master/latex/thesis.pdf).

**Benefit for the Student**

The student will acquire practical experience and be in touch with cutting-edge research in the fields of automated deduction and applied proof theory. He will be mentioned as a co-author of any paper that might benefit from his implementation. He will have the pleasure of programming in the awesome language Scala.

**Benefit for the Project**

Skeptik capability of compressing congruence closure proofs will be improved.

**Requirements**

Solid knowledge of logic, automated deduction and basic proof theory is required. Knowledge of Scala or experience with other object-oriented (e.g. Java, C++,...) and functional (e.g. Haskell, OCaml,...) programming languages and willingness to learn Scala is required. Experience with data structures for proofs or directed acyclic graphs is highly desirable.

**Mentors**

Bruno Woltzenlogel Paleo, Ekaterina Lebedeva

**More information**

Instructions on how to improve your chances of getting accepted are listed on [Skeptik's wiki](https://github.com/Paradoxika/Skeptik/wiki/GSoC-Instructions).


# Members

[Dr. Ekaterina Lebedeva](https://github.com/Paradoxika/Skeptik)
* Mentor for the Skeptik project
![Katya](members/Katya.jpg)

[Dr. Ben Swift](http://benswift.me)
* Mentor for the [Extempore](https://github.com/digego/extempore) project
![Ben](members/Ben.jpg)

[Mr. Andrew Sorensen](https://github.com/digego)
* Mentor for the [Extempore](https://github.com/digego/extempore) project
![Andrew](members/Andrew.jpg)

[Dr. Dinusha Vatsalan](https://cs.anu.edu.au/people/dr-dinusha-vatsalan)
* Mentor for the PriMedLink project
![Dinusha](members/Dinusha.jpg)

[Prof. Peter Christen](https://cs.anu.edu.au/people/Peter.Christen/)
* Mentor for the PriMedLink project
![Peter](members/Peter.jpg)

[Dr. Qing Wang](http://users.cecs.anu.edu.au/~u5170295)
* Mentor for the Rogas project
![Qing](members/Qing.jpg)

[Mr. Minjian Liu](http://people.cecs.anu.edu.au/user/5553)
* Mentor for the Rogas project
![Minjian](members/Minjian.jpg)

[Dr. Bruno Woltzenlogel Paleo](http://paleo.woltzenlogel.org)
* Mentor for the Skeptik project
![Bruno](members/Bruno.jpg)



# Contact

If you have any questions, or would like to know more, then [send us an email](mailto:aossie-gsoc-2016@googlegroups.com) or contact us through our [IRC channel](ToDo).

If you have general questions about the Google Summer of Code program, please read the [FAQ](https://developers.google.com/open-source/gsoc/faq) and the [timeline](https://developers.google.com/open-source/gsoc/timeline) before contacting us. 

Our Address:

	RSISE Building 115
	Research School of Computer Science
	College of Engineering and Computer Science
	Australian National University
	ACT 2601 Acton, Canberra, Australia


# Application Template

Please use the following template for your application. Keep your answers short and concise.

----

**Full Name:**

**Skype Username:**

**Telephone:**

**Address:**

**Country:**

**University:**
**Which degree are you currently pursuing?**
**When do you expect to graduate?**

**Chosen Project:** (indicate here to which of our 4 projects you would like to work.)

**Chosen Idea:** (write here the title of the project idea you have chosen.)

**Proposal:**

(describe here your proposal. It should be slightly more detailed than the chosen idea's description, so that we can check that you have understood it.)

**Timeline:**

Please tell us (in a few sentences or bullet points) what you plan to do in each of the following periods. This will be used to evaluate your performance.

Community Bonding Period (25/04 - 23/05): 

Week 1 (25/05 - 01/06):

Week 2 (02/06 - 08/06):

Week 3 (09/06 - 15/06):

Week 4 (16/06 - 22/06):

*MidTerm Evaluation (27/06)* 

Week 5 (23/06 - 29/06): 

Week 6 (30/06 - 05/07): 

Week 7 (06/07 - 12/07): 

Week 8 (13/07 - 19/07): 

Week 9 (20/07 - 26/07): 

Week 10 (27/07 - 03/08): 

Week 11 (04/08 - 10/08): 

*Suggested "Pencils Down" Date (15/08)*

Week 12 (11/08 - 17/08): 

Week 13 (18/08 - 22/08): 

*Firm "Pencils Down" Date (22/08)*

*Final Evaluation Deadline (29/08)*


**Other Commitments:**

(Please indicate whether you have other commitments (e.g. exams, other projects, theses) during the Google Summer of Code period. Describe how you will prevent these commitments from affecting your performance in your Google Summer of Code project. Inform us how many hours you will be able to work per week.)


**Why are you the best person to execute this proposal?**

(write one or two paragraphs)


**List here software projects for which you worked in the past:**

* (Project 1): (write one sentence describing what the project does.) (mention the programming languages used in this project.) (If you were not the only developer of this project, describe your contributions.) (Include a link to a repository containing the code of this project.)
* ...
* (Project n): (write one sentence describing what the project does.) (mention the programming languages used in this project.) (If you were not the only developer of this project, describe your contributions.) (Include a link to a repository containing the code of this project.)

**List here courses you took at the University, which are relevant for your proposal:**

* (Course 1):  (explain why it is relevant; tell us how your performance in the course was)
* ...
* (Course m): (explain why it is relevant; tell us how your performance in the course was)


**Other information:**

(Include here anything else that you consider relevant to this proposal:)
